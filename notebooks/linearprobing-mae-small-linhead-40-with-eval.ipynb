{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dfb0cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:26:13.773447Z",
     "iopub.status.busy": "2025-05-29T06:26:13.772934Z",
     "iopub.status.idle": "2025-05-29T06:26:13.778950Z",
     "shell.execute_reply": "2025-05-29T06:26:13.778509Z"
    },
    "papermill": {
     "duration": 0.009735,
     "end_time": "2025-05-29T06:26:13.779961",
     "exception": false,
     "start_time": "2025-05-29T06:26:13.770226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_epoch_from_filename(filename):\n",
    "    \n",
    "    match = re.search(r\"train_data_checkpoint_(\\d+)\\.npz$\", filename)\n",
    "    if match:\n",
    "        epoch_str = match.group(1)\n",
    "        epoch_str = \"00\"+epoch_str\n",
    "        return epoch_str[-3:] \n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract epoch number from filename: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b11def",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T06:26:13.783822Z",
     "iopub.status.busy": "2025-05-29T06:26:13.783616Z",
     "iopub.status.idle": "2025-05-29T06:26:20.689868Z",
     "shell.execute_reply": "2025-05-29T06:26:20.689315Z"
    },
    "papermill": {
     "duration": 6.909665,
     "end_time": "2025-05-29T06:26:20.691193",
     "exception": false,
     "start_time": "2025-05-29T06:26:13.781528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "\n",
    "def get_epoch_from_filename(file_name):\n",
    "    name, _ = os.path.splitext(file_name)\n",
    "    epoch_str = name[-3:]\n",
    "    try:\n",
    "        return int(epoch_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def train_on_npz(file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    learning_rate = input_parameters.get(\"learning_rate\", 0.1)\n",
    "    num_epochs = input_parameters.get(\"num_epochs\", 20)\n",
    "    momentum = input_parameters.get(\"momentum\", 0.9)\n",
    "    weight_decay = input_parameters.get(\"weight_decay\", 1e-4)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.BatchNorm1d(input_dim, affine=False, eps=1e-6),\n",
    "        nn.Linear(input_dim, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    del optimizer\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy, model\n",
    "\n",
    "def eval_on_val_file(model, file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def run_linear_probing_on_folder(folder_path, val_folder_path, input_dim, num_classes, input_parameters, csv_path=\"results.csv\"):\n",
    "    files = os.listdir(folder_path)\n",
    "    npz_files = [f for f in files if f.endswith(\".npz\")]\n",
    "    val_files = [f for f in os.listdir(val_folder_path) if f.endswith(\".npz\")]\n",
    "    npz_files.sort(key=lambda file_name: extract_epoch_from_filename(file_name))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for file_name in npz_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        epoch = extract_epoch_from_filename(file_name)\n",
    "        val_file_path = f\"{int(epoch)}\"\n",
    "        val_file_path = os.path.join(val_folder_path, f\"val_data_checkpoint_{int(epoch)}.npz\")\n",
    "        \n",
    "        print(f\"Working on file: {file_name}\")\n",
    "        print(f\"Eval file: {val_file_path}\")\n",
    "        \n",
    "        loss, accuracy, model = train_on_npz(file_path, input_dim, num_classes, input_parameters)\n",
    "        val_accuracy = eval_on_val_file(model, val_file_path, input_dim, num_classes, input_parameters)\n",
    "        print(f\"{epoch} file → Final Avg Loss: {loss:.4f} Final Accuracy: {accuracy:.4f} Val Accuracy: {val_accuracy:.4f}\")\n",
    "        results.append({\"epoch\": epoch, \"loss\": loss, \"accuracy\": accuracy, 'val_accuracy': val_accuracy})\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            save_path = \"/kaggle/working/models/best_model.pth.tar\"\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch_file_epoch': epoch,\n",
    "                'model_state_dict': best_model.state_dict(),\n",
    "                'loss': loss,\n",
    "                'accuracy': best_accuracy,\n",
    "                'val_accuracy': val_accuracy,\n",
    "            }, save_path)\n",
    "            print(f\"Saved new best model with accurcy {best_accuracy * 100:.4f} at {save_path}\")\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    with open(csv_path, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"epoch\", \"loss\", \"accuracy\", \"val_accuracy\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6346a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T06:26:20.695374Z",
     "iopub.status.busy": "2025-05-29T06:26:20.694840Z",
     "iopub.status.idle": "2025-05-29T06:40:57.562679Z",
     "shell.execute_reply": "2025-05-29T06:40:57.561718Z"
    },
    "papermill": {
     "duration": 876.871013,
     "end_time": "2025-05-29T06:40:57.563897",
     "exception": false,
     "start_time": "2025-05-29T06:26:20.692884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file: train_data_checkpoint_1.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 file → Final Avg Loss: 3.7521 Final Accuracy: 0.1493 Val Accuracy: 0.1298\n",
      "Saved new best model with accurcy 14.9292 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_6.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_6.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006 file → Final Avg Loss: 3.5340 Final Accuracy: 0.1904 Val Accuracy: 0.1694\n",
      "Saved new best model with accurcy 19.0400 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_11.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_11.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:36<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011 file → Final Avg Loss: 3.2107 Final Accuracy: 0.2548 Val Accuracy: 0.2114\n",
      "Saved new best model with accurcy 25.4777 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_16.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_16.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "016 file → Final Avg Loss: 3.0970 Final Accuracy: 0.2773 Val Accuracy: 0.2294\n",
      "Saved new best model with accurcy 27.7262 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_21.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_21.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021 file → Final Avg Loss: 3.0139 Final Accuracy: 0.2923 Val Accuracy: 0.2454\n",
      "Saved new best model with accurcy 29.2262 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_26.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_26.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "026 file → Final Avg Loss: 2.9376 Final Accuracy: 0.3060 Val Accuracy: 0.2608\n",
      "Saved new best model with accurcy 30.6023 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_31.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_31.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:36<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031 file → Final Avg Loss: 2.9185 Final Accuracy: 0.3084 Val Accuracy: 0.2544\n",
      "Saved new best model with accurcy 30.8408 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_36.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_36.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "036 file → Final Avg Loss: 2.8712 Final Accuracy: 0.3188 Val Accuracy: 0.2554\n",
      "Saved new best model with accurcy 31.8762 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_41.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_41.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "041 file → Final Avg Loss: 2.8243 Final Accuracy: 0.3258 Val Accuracy: 0.2720\n",
      "Saved new best model with accurcy 32.5846 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_46.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_46.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "046 file → Final Avg Loss: 2.7822 Final Accuracy: 0.3343 Val Accuracy: 0.2798\n",
      "Saved new best model with accurcy 33.4323 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_51.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_51.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "051 file → Final Avg Loss: 2.7257 Final Accuracy: 0.3460 Val Accuracy: 0.2866\n",
      "Saved new best model with accurcy 34.5985 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_56.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_56.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "056 file → Final Avg Loss: 2.6952 Final Accuracy: 0.3514 Val Accuracy: 0.2936\n",
      "Saved new best model with accurcy 35.1446 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_61.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_61.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061 file → Final Avg Loss: 2.6879 Final Accuracy: 0.3523 Val Accuracy: 0.2916\n",
      "Saved new best model with accurcy 35.2308 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_66.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_66.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "066 file → Final Avg Loss: 2.6448 Final Accuracy: 0.3607 Val Accuracy: 0.3062\n",
      "Saved new best model with accurcy 36.0685 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_71.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_71.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "071 file → Final Avg Loss: 2.5779 Final Accuracy: 0.3731 Val Accuracy: 0.3184\n",
      "Saved new best model with accurcy 37.3131 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_76.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_76.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "076 file → Final Avg Loss: 2.5241 Final Accuracy: 0.3845 Val Accuracy: 0.3230\n",
      "Saved new best model with accurcy 38.4531 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_81.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_81.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "081 file → Final Avg Loss: 2.5127 Final Accuracy: 0.3882 Val Accuracy: 0.3270\n",
      "Saved new best model with accurcy 38.8200 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_86.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_86.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "086 file → Final Avg Loss: 2.4881 Final Accuracy: 0.3914 Val Accuracy: 0.3286\n",
      "Saved new best model with accurcy 39.1369 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_91.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_91.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "091 file → Final Avg Loss: 2.4793 Final Accuracy: 0.3942 Val Accuracy: 0.3310\n",
      "Saved new best model with accurcy 39.4192 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_96.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_96.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "096 file → Final Avg Loss: 2.4683 Final Accuracy: 0.3964 Val Accuracy: 0.3348\n",
      "Saved new best model with accurcy 39.6408 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_100.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features/val_data_checkpoint_100.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:37<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 file → Final Avg Loss: 2.4674 Final Accuracy: 0.3970 Val Accuracy: 0.3372\n",
      "Saved new best model with accurcy 39.6977 at /kaggle/working/models/best_model.pth.tar\n",
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "input_params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_epochs\": 40,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "folder = \"/kaggle/input/linearprobing-mae-small-featureextractorreal/extracted_features\"\n",
    "val_folder = \"/kaggle/input/linearprobing-mae-small-featureextractor-real-val/extracted_features\"\n",
    "input_dim = 384\n",
    "num_classes = 100\n",
    "\n",
    "results = run_linear_probing_on_folder(folder, val_folder, input_dim, num_classes, input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea62b2",
   "metadata": {
    "papermill": {
     "duration": 0.035133,
     "end_time": "2025-05-29T06:40:57.634568",
     "exception": false,
     "start_time": "2025-05-29T06:40:57.599435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 242416397,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 242481465,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 892.496852,
   "end_time": "2025-05-29T06:41:00.509145",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T06:26:08.012293",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
