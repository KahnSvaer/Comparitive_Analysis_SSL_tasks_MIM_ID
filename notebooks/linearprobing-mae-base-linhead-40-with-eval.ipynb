{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ddd2bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:35:09.924241Z",
     "iopub.status.busy": "2025-05-29T07:35:09.924041Z",
     "iopub.status.idle": "2025-05-29T07:35:09.930268Z",
     "shell.execute_reply": "2025-05-29T07:35:09.929650Z"
    },
    "papermill": {
     "duration": 0.009951,
     "end_time": "2025-05-29T07:35:09.931300",
     "exception": false,
     "start_time": "2025-05-29T07:35:09.921349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_epoch_from_filename(filename):\n",
    "    \n",
    "    match = re.search(r\"train_data_checkpoint_(\\d+)\\.npz$\", filename)\n",
    "    if match:\n",
    "        epoch_str = match.group(1)\n",
    "        epoch_str = \"00\"+epoch_str\n",
    "        return epoch_str[-3:] \n",
    "    else:\n",
    "        raise ValueError(f\"Could not extract epoch number from filename: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8b16d2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T07:35:09.935259Z",
     "iopub.status.busy": "2025-05-29T07:35:09.935031Z",
     "iopub.status.idle": "2025-05-29T07:35:13.960065Z",
     "shell.execute_reply": "2025-05-29T07:35:13.959488Z"
    },
    "papermill": {
     "duration": 4.028474,
     "end_time": "2025-05-29T07:35:13.961367",
     "exception": false,
     "start_time": "2025-05-29T07:35:09.932893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "\n",
    "def get_epoch_from_filename(file_name):\n",
    "    name, _ = os.path.splitext(file_name)\n",
    "    epoch_str = name[-3:]\n",
    "    try:\n",
    "        return int(epoch_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def train_on_npz(file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    learning_rate = input_parameters.get(\"learning_rate\", 0.1)\n",
    "    num_epochs = input_parameters.get(\"num_epochs\", 20)\n",
    "    momentum = input_parameters.get(\"momentum\", 0.9)\n",
    "    weight_decay = input_parameters.get(\"weight_decay\", 1e-4)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.BatchNorm1d(input_dim, affine=False, eps=1e-6),\n",
    "        nn.Linear(input_dim, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    del optimizer\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy, model\n",
    "\n",
    "def eval_on_val_file(model, file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def run_linear_probing_on_folder(folder_path, val_folder_path, input_dim, num_classes, input_parameters, csv_path=\"results.csv\"):\n",
    "    if type(folder) in (list, tuple):\n",
    "        files = []\n",
    "        for files_folders in folder_path:\n",
    "            files += [os.path.join(files_folders, f) for f in os.listdir(files_folders)]\n",
    "    else:\n",
    "        files = [os.path.join(folder_path, f) for f in os.listdir(folder_path)]\n",
    "        \n",
    "    npz_files = [f for f in files if f.endswith(\".npz\")]\n",
    "    val_files = [f for f in os.listdir(val_folder_path) if f.endswith(\".npz\")]\n",
    "    npz_files.sort(key=lambda file_name: extract_epoch_from_filename(file_name))\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for file_name in npz_files:\n",
    "        epoch = extract_epoch_from_filename(file_name)\n",
    "        val_file_path = f\"{int(epoch)}\"\n",
    "        val_file_path = os.path.join(val_folder_path, f\"val_data_checkpoint_{int(epoch)}.npz\")\n",
    "        \n",
    "        print(f\"Working on file: {file_name}\")\n",
    "        print(f\"Eval file: {val_file_path}\")\n",
    "        \n",
    "        loss, accuracy, model = train_on_npz(file_name, input_dim, num_classes, input_parameters)\n",
    "        val_accuracy = eval_on_val_file(model, val_file_path, input_dim, num_classes, input_parameters)\n",
    "        print(f\"{epoch} file → Final Avg Loss: {loss:.4f} Final Accuracy: {accuracy:.4f} Val Accuracy: {val_accuracy:.4f}\")\n",
    "        results.append({\"epoch\": epoch, \"loss\": loss, \"accuracy\": accuracy, 'val_accuracy': val_accuracy})\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            save_path = \"/kaggle/working/models/best_model.pth.tar\"\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch_file_epoch': epoch,\n",
    "                'model_state_dict': best_model.state_dict(),\n",
    "                'loss': loss,\n",
    "                'accuracy': best_accuracy,\n",
    "                'val_accuracy': val_accuracy,\n",
    "            }, save_path)\n",
    "            print(f\"Saved new best model with accurcy {best_accuracy * 100:.4f} at {save_path}\")\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    with open(csv_path, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"epoch\", \"loss\", \"accuracy\", \"val_accuracy\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1182bc63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:35:13.965586Z",
     "iopub.status.busy": "2025-05-29T07:35:13.965265Z",
     "iopub.status.idle": "2025-05-29T07:53:16.202494Z",
     "shell.execute_reply": "2025-05-29T07:53:16.201656Z"
    },
    "papermill": {
     "duration": 1082.240577,
     "end_time": "2025-05-29T07:53:16.203713",
     "exception": false,
     "start_time": "2025-05-29T07:35:13.963136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_1.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_1.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 file → Final Avg Loss: 3.6800 Final Accuracy: 0.1637 Val Accuracy: 0.1458\n",
      "Saved new best model with accurcy 16.3677 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_6.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_6.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006 file → Final Avg Loss: 3.4884 Final Accuracy: 0.2008 Val Accuracy: 0.1686\n",
      "Saved new best model with accurcy 20.0846 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_11.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_11.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011 file → Final Avg Loss: 3.0780 Final Accuracy: 0.2818 Val Accuracy: 0.1948\n",
      "Saved new best model with accurcy 28.1754 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_16.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_16.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "016 file → Final Avg Loss: 3.0471 Final Accuracy: 0.2844 Val Accuracy: 0.2098\n",
      "Saved new best model with accurcy 28.4377 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_21.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_21.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021 file → Final Avg Loss: 2.9237 Final Accuracy: 0.3099 Val Accuracy: 0.2252\n",
      "Saved new best model with accurcy 30.9877 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_26.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_26.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "026 file → Final Avg Loss: 2.8249 Final Accuracy: 0.3288 Val Accuracy: 0.2404\n",
      "Saved new best model with accurcy 32.8785 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_31.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_31.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031 file → Final Avg Loss: 2.7420 Final Accuracy: 0.3448 Val Accuracy: 0.2560\n",
      "Saved new best model with accurcy 34.4800 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_36.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_36.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "036 file → Final Avg Loss: 2.7375 Final Accuracy: 0.3468 Val Accuracy: 0.2622\n",
      "Saved new best model with accurcy 34.6815 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_41.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_41.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "041 file → Final Avg Loss: 2.6974 Final Accuracy: 0.3519 Val Accuracy: 0.2718\n",
      "Saved new best model with accurcy 35.1869 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_46.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_46.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "046 file → Final Avg Loss: 2.6487 Final Accuracy: 0.3632 Val Accuracy: 0.2798\n",
      "Saved new best model with accurcy 36.3177 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_51.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_51.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "051 file → Final Avg Loss: 2.6399 Final Accuracy: 0.3654 Val Accuracy: 0.2874\n",
      "Saved new best model with accurcy 36.5408 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_56.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_56.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "056 file → Final Avg Loss: 2.5480 Final Accuracy: 0.3838 Val Accuracy: 0.3010\n",
      "Saved new best model with accurcy 38.3769 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_61.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_61.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "061 file → Final Avg Loss: 2.5672 Final Accuracy: 0.3797 Val Accuracy: 0.3052\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_66.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_66.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "066 file → Final Avg Loss: 2.5307 Final Accuracy: 0.3875 Val Accuracy: 0.3118\n",
      "Saved new best model with accurcy 38.7538 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70/train_data_checkpoint_71.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_71.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "071 file → Final Avg Loss: 2.4815 Final Accuracy: 0.3987 Val Accuracy: 0.3244\n",
      "Saved new best model with accurcy 39.8654 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_76.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_76.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "076 file → Final Avg Loss: 2.4673 Final Accuracy: 0.4020 Val Accuracy: 0.3252\n",
      "Saved new best model with accurcy 40.1992 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_81.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_81.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "081 file → Final Avg Loss: 2.4162 Final Accuracy: 0.4123 Val Accuracy: 0.3370\n",
      "Saved new best model with accurcy 41.2262 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_86.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_86.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "086 file → Final Avg Loss: 2.3942 Final Accuracy: 0.4170 Val Accuracy: 0.3348\n",
      "Saved new best model with accurcy 41.6962 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_91.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_91.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "091 file → Final Avg Loss: 2.3909 Final Accuracy: 0.4180 Val Accuracy: 0.3384\n",
      "Saved new best model with accurcy 41.7969 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_96.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_96.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "096 file → Final Avg Loss: 2.3846 Final Accuracy: 0.4193 Val Accuracy: 0.3400\n",
      "Saved new best model with accurcy 41.9308 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: /kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features/train_data_checkpoint_100.npz\n",
      "Eval file: /kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features/val_data_checkpoint_100.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 file → Final Avg Loss: 2.3834 Final Accuracy: 0.4193 Val Accuracy: 0.3374\n",
      "Saved new best model with accurcy 41.9315 at /kaggle/working/models/best_model.pth.tar\n",
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "input_params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_epochs\": 40,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "folder = (\"/kaggle/input/linearprobing-mae-base-featureextractorreal-2/extracted_features\",\"/kaggle/input/train-data-checkpoint-mae-base-1-70/train_data_checkpoint_mae_base_1-70\")\n",
    "val_folder = \"/kaggle/input/linearprobing-mae-base-featureextractorreal-val/extracted_features\"\n",
    "input_dim = 768\n",
    "num_classes = 100\n",
    "\n",
    "results = run_linear_probing_on_folder(folder, val_folder, input_dim, num_classes, input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5cfec",
   "metadata": {
    "papermill": {
     "duration": 0.034958,
     "end_time": "2025-05-29T07:53:16.274714",
     "exception": false,
     "start_time": "2025-05-29T07:53:16.239756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7542963,
     "sourceId": 11992291,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 242471622,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 242475763,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1092.893344,
   "end_time": "2025-05-29T07:53:18.697560",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T07:35:05.804216",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
