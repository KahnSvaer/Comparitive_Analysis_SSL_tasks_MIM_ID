{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c63daa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:43:21.220448Z",
     "iopub.status.busy": "2025-05-29T07:43:21.220248Z",
     "iopub.status.idle": "2025-05-29T07:43:21.227000Z",
     "shell.execute_reply": "2025-05-29T07:43:21.226349Z"
    },
    "papermill": {
     "duration": 0.010478,
     "end_time": "2025-05-29T07:43:21.228171",
     "exception": false,
     "start_time": "2025-05-29T07:43:21.217693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_epoch_from_filename(file_path):\n",
    "    base = os.path.basename(file_path)  # e.g. 'train_data_checkpoint_005.npz'\n",
    "    name, _ = os.path.splitext(base)    # e.g. 'train_data_checkpoint_005'\n",
    "    epoch_str = \"000\"+name               # last 3 chars before extension, e.g. '005'\n",
    "    return epoch_str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9227ed09",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T07:43:21.231884Z",
     "iopub.status.busy": "2025-05-29T07:43:21.231714Z",
     "iopub.status.idle": "2025-05-29T07:43:25.924395Z",
     "shell.execute_reply": "2025-05-29T07:43:25.923790Z"
    },
    "papermill": {
     "duration": 4.695991,
     "end_time": "2025-05-29T07:43:25.925705",
     "exception": false,
     "start_time": "2025-05-29T07:43:21.229714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "def train_on_npz(file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    learning_rate = input_parameters.get(\"learning_rate\", 0.1)\n",
    "    num_epochs = input_parameters.get(\"num_epochs\", 20)\n",
    "    momentum = input_parameters.get(\"momentum\", 0.9)\n",
    "    weight_decay = input_parameters.get(\"weight_decay\", 1e-4)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.BatchNorm1d(input_dim, affine=False, eps=1e-6),\n",
    "        nn.Linear(input_dim, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0.0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    del optimizer\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy, model\n",
    "\n",
    "def eval_on_val_file(model, file_path, input_dim, num_classes, input_parameters):\n",
    "    batch_size = input_parameters.get(\"batch_size\", 256)\n",
    "    device = input_parameters.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    data = np.load(file_path)\n",
    "    X = torch.from_numpy(data[\"features\"]).float()\n",
    "    y = torch.from_numpy(data[\"labels\"]).long()\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            logits = model(batch_X)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def run_linear_probing_on_folder(folder_path, val_folder_path, input_dim, num_classes, input_parameters, csv_path=\"results.csv\"):\n",
    "    files = os.listdir(folder_path)\n",
    "    npz_files = [f for f in files if f.endswith(\".npz\")]\n",
    "    val_files = [f for f in os.listdir(val_folder_path) if f.endswith(\".npz\")]\n",
    "    npz_files.sort()\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for file_name in npz_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        epoch = get_epoch_from_filename(file_name)\n",
    "        epoch = \"00\"+epoch\n",
    "        val_file_path = os.path.join(val_folder_path, f\"val_data_checkpoint_{epoch[-3:]}.npz\")\n",
    "        \n",
    "        print(f\"Working on file: {file_name}\")\n",
    "        print(f\"Eval file: {val_file_path}\")\n",
    "        \n",
    "        loss, accuracy, model = train_on_npz(file_path, input_dim, num_classes, input_parameters)\n",
    "        val_accuracy = eval_on_val_file(model, val_file_path, input_dim, num_classes, input_parameters)\n",
    "        print(f\"{epoch} file → Final Avg Loss: {loss:.4f} Final Accuracy: {accuracy:.4f} Val Accuracy: {val_accuracy:.4f}\")\n",
    "        results.append({\"epoch\": epoch, \"loss\": loss, \"accuracy\": accuracy, 'val_accuracy': val_accuracy})\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            save_path = \"/kaggle/working/models/best_model.pth.tar\"\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            torch.save({\n",
    "                'epoch_file_epoch': epoch,\n",
    "                'model_state_dict': best_model.state_dict(),\n",
    "                'loss': loss,\n",
    "                'accuracy': best_accuracy,\n",
    "                'val_accuracy': val_accuracy,\n",
    "            }, save_path)\n",
    "            print(f\"Saved new best model with accurcy {best_accuracy * 100:.4f} at {save_path}\")\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    with open(csv_path, mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"epoch\", \"loss\", \"accuracy\", \"val_accuracy\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"Results saved to {csv_path}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4b84e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T07:43:25.929598Z",
     "iopub.status.busy": "2025-05-29T07:43:25.929322Z",
     "iopub.status.idle": "2025-05-29T08:09:21.388609Z",
     "shell.execute_reply": "2025-05-29T08:09:21.387649Z"
    },
    "papermill": {
     "duration": 1555.462567,
     "end_time": "2025-05-29T08:09:21.389908",
     "exception": false,
     "start_time": "2025-05-29T07:43:25.927341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file: train_data_checkpoint_005.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_005.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00005 file → Final Avg Loss: 2.8985 Final Accuracy: 0.3077 Val Accuracy: 0.2128\n",
      "Saved new best model with accurcy 30.7677 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_010.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_010.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00010 file → Final Avg Loss: 2.6041 Final Accuracy: 0.3690 Val Accuracy: 0.2568\n",
      "Saved new best model with accurcy 36.9038 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_015.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_015.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00015 file → Final Avg Loss: 2.4149 Final Accuracy: 0.4078 Val Accuracy: 0.2976\n",
      "Saved new best model with accurcy 40.7838 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_020.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_020.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00020 file → Final Avg Loss: 2.2978 Final Accuracy: 0.4325 Val Accuracy: 0.3172\n",
      "Saved new best model with accurcy 43.2492 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_025.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_025.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00025 file → Final Avg Loss: 2.1750 Final Accuracy: 0.4610 Val Accuracy: 0.3396\n",
      "Saved new best model with accurcy 46.0985 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_030.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_030.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00030 file → Final Avg Loss: 2.0802 Final Accuracy: 0.4821 Val Accuracy: 0.3534\n",
      "Saved new best model with accurcy 48.2092 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_035.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_035.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00035 file → Final Avg Loss: 2.0328 Final Accuracy: 0.4927 Val Accuracy: 0.3604\n",
      "Saved new best model with accurcy 49.2708 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_040.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_040.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00040 file → Final Avg Loss: 1.9308 Final Accuracy: 0.5155 Val Accuracy: 0.3856\n",
      "Saved new best model with accurcy 51.5508 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_045.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_045.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00045 file → Final Avg Loss: 1.8654 Final Accuracy: 0.5305 Val Accuracy: 0.3900\n",
      "Saved new best model with accurcy 53.0462 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_050.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_050.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00050 file → Final Avg Loss: 1.8211 Final Accuracy: 0.5416 Val Accuracy: 0.3976\n",
      "Saved new best model with accurcy 54.1646 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_055.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_055.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00055 file → Final Avg Loss: 1.7811 Final Accuracy: 0.5510 Val Accuracy: 0.4002\n",
      "Saved new best model with accurcy 55.0985 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_060.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_060.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00060 file → Final Avg Loss: 1.7346 Final Accuracy: 0.5607 Val Accuracy: 0.4074\n",
      "Saved new best model with accurcy 56.0738 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_065.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_065.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00065 file → Final Avg Loss: 1.6842 Final Accuracy: 0.5720 Val Accuracy: 0.4202\n",
      "Saved new best model with accurcy 57.1992 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_070.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_070.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00070 file → Final Avg Loss: 1.6710 Final Accuracy: 0.5763 Val Accuracy: 0.4270\n",
      "Saved new best model with accurcy 57.6277 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_075.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_075.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00075 file → Final Avg Loss: 1.5938 Final Accuracy: 0.5938 Val Accuracy: 0.4322\n",
      "Saved new best model with accurcy 59.3823 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_080.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_080.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00080 file → Final Avg Loss: 1.5488 Final Accuracy: 0.6046 Val Accuracy: 0.4422\n",
      "Saved new best model with accurcy 60.4638 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_085.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_085.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00085 file → Final Avg Loss: 1.5255 Final Accuracy: 0.6106 Val Accuracy: 0.4422\n",
      "Saved new best model with accurcy 61.0638 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_090.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_090.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:00<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00090 file → Final Avg Loss: 1.4765 Final Accuracy: 0.6236 Val Accuracy: 0.4496\n",
      "Saved new best model with accurcy 62.3577 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_095.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_095.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00095 file → Final Avg Loss: 1.4454 Final Accuracy: 0.6284 Val Accuracy: 0.4546\n",
      "Saved new best model with accurcy 62.8377 at /kaggle/working/models/best_model.pth.tar\n",
      "Working on file: train_data_checkpoint_100.npz\n",
      "Eval file: /kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features/val_data_checkpoint_100.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00100 file → Final Avg Loss: 1.4108 Final Accuracy: 0.6386 Val Accuracy: 0.4568\n",
      "Saved new best model with accurcy 63.8615 at /kaggle/working/models/best_model.pth.tar\n",
      "Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "input_params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"num_epochs\": 40,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "\n",
    "folder = \"/kaggle/input/linearprobing-simclr-featureextractor-train/extracted_features\"\n",
    "val_folder = \"/kaggle/input/linearprobing-simclr-featureextractor-valid/extracted_features\"\n",
    "input_dim = 2048\n",
    "num_classes = 100\n",
    "\n",
    "results = run_linear_probing_on_folder(folder, val_folder, input_dim, num_classes, input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3b503",
   "metadata": {
    "papermill": {
     "duration": 0.033382,
     "end_time": "2025-05-29T08:09:21.457600",
     "exception": false,
     "start_time": "2025-05-29T08:09:21.424218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 242351500,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 242478268,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1567.282365,
   "end_time": "2025-05-29T08:09:24.456060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-29T07:43:17.173695",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
